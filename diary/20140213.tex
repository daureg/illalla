\section*{Week goals}
\begin{itemize}
	\item Get bounding box of 10 cities in the US and 10 in Europe.
	\item Get Flickr data for Helsinki (pre processing?, heatmap with
		leaflet?).
	\item Filter Foursquare dataset to these cities and find a way to store
		the result:
		\begin{itemize}
			\item cPickle, which is
				\href{http://www.shocksolution.com/2010/01/storing-large-numpy-arrays-on-disk-python-pickle-vs-hdf5adsf/}{slow
				and memory hungry}.
			\item \href{https://github.com/telegraphic/hickle}{HDF5}
			\item \href{https://github.com/msgpack/msgpack-python}{MessagePack}
			\item MongoDB
			\item SQL
		\end{itemize}
		Can also test
		\href{http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html}{kd-tree}
		(maybe overkill), PyPy and Julia.
\end{itemize}

\section*{Week results}
\begin{itemize}
	\item According to \href{http://www.4sqstat.com/}{4sqstat.com}, the 10
		more popular cities in the US are: New York, Washington, San
		Francisco, Atlanta, Indianapolis, Los Angeles, Seattle,
		Houston, St\. Louis and Chicago\. Plus a biased selection of European
		cities: London, Paris, Berlin, Rome, Prague, Moscow, Amsterdam,
		Helsinki, Stockholm and Barcelona. There also a
		\href{https://en.wikipedia.org/wiki/Largest\_cities\_of\_the\_European\_Union\_by\_population\_within\_city\_limits}{Wikipedia
		list of EU} cities by population.
	\item Find \numprint{21294} tagged photos in Helsinki, which is not a lot (less than
		Nantes!). Haven't done any pre processing so far.
	\item Filtering the dataset took around 7 minutes (in plain python with
		binary search to find corresponding city) using the whole file at
		once (and without cutting it to process it in parallel with several
		nodes) and gave the results shown in Table~\vref{tab:cities}:
		\begin{table}[ht]
			\centering
			\begin{tabular}{ll}
				\toprule
				region       & checkin count \\
				\midrule
				newyork      & \numprint{609353} \\
				losangeles   & \numprint{258838} \\
				chicago      & \numprint{201155} \\
				sanfrancisco & \numprint{190448} \\
				london       & \numprint{141784} \\
				washington   & \numprint{119654} \\
				seattle      & \numprint{84342} \\
				amsterdam    & \numprint{67971} \\
				houston      & \numprint{62768} \\
				atlanta      & \numprint{61958} \\
				paris        & \numprint{53642} \\
				stockholm    & \numprint{53241} \\
				indianapolis & \numprint{47546} \\
				moscow       & \numprint{46598} \\
				barcelona    & \numprint{37146} \\
				berlin       & \numprint{35727} \\
				stlouis      & \numprint{26239} \\
				rome         & \numprint{14022} \\
				prague       & \numprint{11960} \\
				helsinki     & \numprint{9357} \\
				total        & \numprint{2133749} \\
				\bottomrule
			\end{tabular}
			\caption{Check in count\label{tab:cities}}
		\end{table}
		I ended up storing each checkin in \texttt{foursquare.checkins}
		database in MongoDB with the following form: \texttt{('CheckIn',
		['\_id', 'lid', 'uid', 'city', 'loc', 'time'])}. But I started query
		Foursquare API for venue, I realized that the field \texttt{PlaceID}
		in the dataset was no more valid (maybe because
		\href{http://aboutfoursquare.com/foursquare-venue-urls-change-format/}{the
		id format changes in September 2011}). Yet check in come with a tweet
		that often ($72.94\%$) contains a URL, which in many case ultimately
		points to the Foursquare venue page. Either the page URL or page
		content provide the venue id. Thus I use
		\href{http://pycurl.sourceforge.net/doc/curlmultiobject.html}{pycurl}
		to follow these links (by batch of 30) but it takes more time and some
		of them do not lead to Foursquare or are dead.
	\item Using a python binding to Foursquare API, I also started
		building venue profile that look like this:
			\begin{verbatim}
namedtuple('Venue', ['id', 'name', 'loc', 'cats', 'cat', 'stats', 'hours',
                     'price', 'rating', 'createdAt', 'mayor', 'tags',
                     'shortUrl', 'canonicalUrl', 'likes', 'likers'])
\end{verbatim}
		But I need venue id to continue
\end{itemize}

\section*{Follow up}
\begin{itemize}
	\item Leaflet heatmap (that is probably not very useful per se but
		hopefully it will provide better visualisation in the future)
\end{itemize}

\section*{Activity}
\begin{verbatim}
a class that make request to 4SQ API regarding venue and categories
A	AskFourquare.py
use tweet URL but try to avoid irrelevant ones
M	VenueIdCrawler.py
M	read_foursquare.py
update project info
M	.gitignore
M	README.md
active more package for writing diary
M	diary/preambule.tex
cope with vanity url
M	VenueIdCrawler.py
cache url expansion results
M	VenueIdCrawler.py
add a class to convert short url to venue id
A	VenueIdCrawler.py
insert checkin into mongoDB
M	read_foursquare.py
always split on longitude so it's now a binary search tree
M	read_foursquare.py
start filtering foursquare dataset
M	cities.py
A	read_foursquare.py
try to get 4sq venue from flickr tag
M	grab_photos.py
grab photos from new cities on triton
M	cities.py
M	grab_photos.py
add a list of cities
A	cities.py
read more papers
A	papers/place_similarity.md
A	papers/traj.md
\end{verbatim}
